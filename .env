# ==========================================
# RuvBot Model & Reasoning Configuration (Phase 8 Corrected)
# ==========================================

# High-reasoning tier for Architect/Queen logic (Updated to available Pro tier)
COORDINATOR_MODEL="gemini-3-pro-preview"

# Next-gen execution tier for Worker/Specialist logic (Updated for Speed/SLA)
WORKER_MODEL="gemini-2.5-flash"

# Reasoning Control (Thinking Mode)
# Levels: minimal, low, medium, high (High is required for London School TDD)
GEMINI_THINKING_LEVEL="high"

# Performance & Stability
CLAUDE_FLOW_FALLBACK="false"

# 38ms SLA Weighting (Higher = Prioritize speed over verbose reasoning)
RUVBOT_SLA_SPEED_BIAS="0.8"

# ==========================================
# Authentication
# ==========================================
GOOGLE_API_KEY="${GOOGLE_API_KEY}"

# ==========================================
# Ollama Local Fallback (Bridge)
# ==========================================
# This redirects standard Claude-style calls to your local Ollama port
ANTHROPIC_BASE_URL="http://localhost:11434"
ANTHROPIC_API_KEY="ollama" # Required placeholder for the SDK to engage

# Define your local failover model (matches your PRD.md logic)
LOCAL_WORKER_MODEL="qwen2.5-coder:7b"
